{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Lord of The RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base code:\n",
    "https://github.com/udacity/deep-learning/blob/master/intro-to-rnns/Anna_KaRNNa.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, sys, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all the books that will be used.\n",
    "\n",
    "Creating a vocabulary containing all existing characters and two dictionaries that map the character to an integer and an integer to a character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "booksPath = 'books'\n",
    "text = ''\n",
    "\n",
    "for book in sorted([book for book in os.listdir(booksPath) if os.path.isfile(os.path.join(booksPath, book))]):\n",
    "    with open(booksPath+'/'+book, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if re.match(r'^\\s*$', line) != True:\n",
    "                text += line\n",
    "                \n",
    "vocab = sorted(set(text))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_vocab = {}\n",
    "dict_vocab[\"vocab\"] = vocab\n",
    "dict_vocab[\"vocab_to_int\"] = vocab_to_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 34, 39, 46, 37, 34, 39, 29, 26, 37, 82,  1,  1,  1, 45, 59, 56,\n",
       "        2, 38, 72, 70, 60, 54,  2, 66, 57,  2, 71, 59, 56,  2, 26, 60, 65,\n",
       "       72, 69,  1,  1,  1,  1, 45, 59, 56, 69, 56,  2, 74, 52, 70,  2, 30,\n",
       "       69, 72,  9,  2, 71, 59, 56,  2, 40, 65, 56,  9,  2, 74, 59, 66,  2,\n",
       "       60, 65,  2, 26, 69, 55, 52,  2, 60, 70,  2, 54, 52, 63, 63, 56, 55,\n",
       "        2, 34, 63, 98, 73, 52, 71, 52, 69, 23,  2, 52, 65, 55,  2], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AINULINDALË\\n\\n\\nThe Music of the Ainur\\n\\n\\n\\nThere was Eru, the One, who in Arda is called Ilúvatar; and '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the number of characters per batch and number of batches we can make\n",
    "    characters_per_batch = n_seqs * n_steps\n",
    "    n_batches = len(arr)//characters_per_batch\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * characters_per_batch]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[ 26  34  39  46  37  34  39  29  26  37]\n",
      " [ 60  70  59   2  60  71  11   2  45  59]\n",
      " [ 70  60  63  55  72  69   9   2  53  72]\n",
      " [ 63  56  52  70  56   2  66  69   2  53]\n",
      " [ 59  72  69  69  60  56  55   2  72  67]\n",
      " [ 66   2  64  56   2  58  69  52  73  56]\n",
      " [ 66  71   2  52  65  70  74  56  69   2]\n",
      " [ 66  69  65  11   2 103  48  56   2  57]\n",
      " [ 71   2  71  59  56  64   9   2  54  66]\n",
      " [ 52  70   2  71  66  66   2  70  59  66]]\n",
      "\n",
      "y\n",
      " [[ 34  39  46  37  34  39  29  26  37  82]\n",
      " [ 70  59   2  60  71  11   2  45  59  56]\n",
      " [ 60  63  55  72  69   9   2  53  72  60]\n",
      " [ 56  52  70  56   2  66  69   2  53  56]\n",
      " [ 72  69  69  60  56  55   2  72  67   2]\n",
      " [  2  64  56   2  58  69  52  73  56  63]\n",
      " [ 71   2  52  65  70  74  56  69   2  52]\n",
      " [ 69  65  11   2 103  48  56   2  57  56]\n",
      " [  2  71  59  56  64   9   2  54  66  63]\n",
      " [ 70   2  71  66  66   2  70  59  66  69]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        # Use a basic LSTM cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        x: Input tensor\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # That is, the shape should be batch_size*num_steps rows by lstm_size columns\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # One-hot encode targets and reshape to match logits, one row per batch_size per step\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        \n",
    "        # Run each sequence step through the RNN and collect the outputs\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10         # Sequences per batch\n",
    "num_steps = 50          # Number of sequence steps per batch\n",
    "lstm_size = 128         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.01    # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15...  Training Step: 1000...  Training loss: 2.0783...  0.1644 sec/batch\n",
      "Epoch: 1/15...  Training Step: 2000...  Training loss: 1.7992...  0.0839 sec/batch\n",
      "Epoch: 1/15...  Training Step: 3000...  Training loss: 1.8999...  0.0862 sec/batch\n",
      "Epoch: 1/15...  Training Step: 4000...  Training loss: 1.7004...  0.1201 sec/batch\n",
      "Epoch: 1/15...  Training Step: 5000...  Training loss: 1.7649...  0.0881 sec/batch\n",
      "Epoch: 1/15...  Training Step: 6000...  Training loss: 1.5744...  0.0856 sec/batch\n",
      "Epoch: 1/15...  Training Step: 7000...  Training loss: 1.7017...  0.0865 sec/batch\n",
      "Epoch: 2/15...  Training Step: 8000...  Training loss: 1.7101...  0.0839 sec/batch\n",
      "Epoch: 2/15...  Training Step: 9000...  Training loss: 1.7555...  0.0857 sec/batch\n",
      "Epoch: 2/15...  Training Step: 10000...  Training loss: 1.6890...  0.1117 sec/batch\n",
      "Epoch: 2/15...  Training Step: 11000...  Training loss: 1.7097...  0.2199 sec/batch\n",
      "Epoch: 2/15...  Training Step: 12000...  Training loss: 1.7094...  0.1198 sec/batch\n",
      "Epoch: 2/15...  Training Step: 13000...  Training loss: 1.6812...  0.1217 sec/batch\n",
      "Epoch: 2/15...  Training Step: 14000...  Training loss: 1.6297...  0.0854 sec/batch\n",
      "Epoch: 2/15...  Training Step: 15000...  Training loss: 1.7533...  0.1087 sec/batch\n",
      "Epoch: 3/15...  Training Step: 16000...  Training loss: 1.7945...  0.1172 sec/batch\n",
      "Epoch: 3/15...  Training Step: 17000...  Training loss: 1.6684...  0.1022 sec/batch\n",
      "Epoch: 3/15...  Training Step: 18000...  Training loss: 1.7606...  0.0881 sec/batch\n",
      "Epoch: 3/15...  Training Step: 19000...  Training loss: 1.6441...  0.0919 sec/batch\n",
      "Epoch: 3/15...  Training Step: 20000...  Training loss: 1.5885...  0.0855 sec/batch\n",
      "Epoch: 3/15...  Training Step: 21000...  Training loss: 1.6441...  0.0843 sec/batch\n",
      "Epoch: 3/15...  Training Step: 22000...  Training loss: 1.7448...  0.0854 sec/batch\n",
      "Epoch: 4/15...  Training Step: 23000...  Training loss: 1.5735...  0.1261 sec/batch\n",
      "Epoch: 4/15...  Training Step: 24000...  Training loss: 1.8513...  0.1114 sec/batch\n",
      "Epoch: 4/15...  Training Step: 25000...  Training loss: 1.5818...  0.1027 sec/batch\n",
      "Epoch: 4/15...  Training Step: 26000...  Training loss: 1.5408...  0.1083 sec/batch\n",
      "Epoch: 4/15...  Training Step: 27000...  Training loss: 1.7170...  0.1247 sec/batch\n",
      "Epoch: 4/15...  Training Step: 28000...  Training loss: 1.5012...  0.1094 sec/batch\n",
      "Epoch: 4/15...  Training Step: 29000...  Training loss: 1.6607...  0.1182 sec/batch\n",
      "Epoch: 4/15...  Training Step: 30000...  Training loss: 1.5540...  0.1244 sec/batch\n",
      "Epoch: 5/15...  Training Step: 31000...  Training loss: 1.6275...  0.0853 sec/batch\n",
      "Epoch: 5/15...  Training Step: 32000...  Training loss: 1.7426...  0.1217 sec/batch\n",
      "Epoch: 5/15...  Training Step: 33000...  Training loss: 1.7100...  0.1132 sec/batch\n",
      "Epoch: 5/15...  Training Step: 34000...  Training loss: 1.5318...  0.1125 sec/batch\n",
      "Epoch: 5/15...  Training Step: 35000...  Training loss: 1.5903...  0.1158 sec/batch\n",
      "Epoch: 5/15...  Training Step: 36000...  Training loss: 1.5863...  0.1136 sec/batch\n",
      "Epoch: 5/15...  Training Step: 37000...  Training loss: 1.6184...  0.1042 sec/batch\n",
      "Epoch: 5/15...  Training Step: 38000...  Training loss: 1.7961...  0.1065 sec/batch\n",
      "Epoch: 6/15...  Training Step: 39000...  Training loss: 1.5331...  0.1151 sec/batch\n",
      "Epoch: 6/15...  Training Step: 40000...  Training loss: 1.5456...  0.1163 sec/batch\n",
      "Epoch: 6/15...  Training Step: 41000...  Training loss: 1.5647...  0.0869 sec/batch\n",
      "Epoch: 6/15...  Training Step: 42000...  Training loss: 1.5479...  0.0841 sec/batch\n",
      "Epoch: 6/15...  Training Step: 43000...  Training loss: 1.5773...  0.0887 sec/batch\n",
      "Epoch: 6/15...  Training Step: 44000...  Training loss: 1.6738...  0.0908 sec/batch\n",
      "Epoch: 6/15...  Training Step: 45000...  Training loss: 1.6502...  0.0877 sec/batch\n",
      "Epoch: 7/15...  Training Step: 46000...  Training loss: 1.6718...  0.0868 sec/batch\n",
      "Epoch: 7/15...  Training Step: 47000...  Training loss: 1.7278...  0.1545 sec/batch\n",
      "Epoch: 7/15...  Training Step: 48000...  Training loss: 1.7379...  0.0965 sec/batch\n",
      "Epoch: 7/15...  Training Step: 49000...  Training loss: 1.6826...  0.0823 sec/batch\n",
      "Epoch: 7/15...  Training Step: 50000...  Training loss: 1.6714...  0.0898 sec/batch\n",
      "Epoch: 7/15...  Training Step: 51000...  Training loss: 1.6374...  0.0891 sec/batch\n",
      "Epoch: 7/15...  Training Step: 52000...  Training loss: 1.6637...  0.0896 sec/batch\n",
      "Epoch: 7/15...  Training Step: 53000...  Training loss: 1.7334...  0.0839 sec/batch\n",
      "Epoch: 8/15...  Training Step: 54000...  Training loss: 1.6400...  0.0949 sec/batch\n",
      "Epoch: 8/15...  Training Step: 55000...  Training loss: 1.5394...  0.0953 sec/batch\n",
      "Epoch: 8/15...  Training Step: 56000...  Training loss: 1.6500...  0.0925 sec/batch\n",
      "Epoch: 8/15...  Training Step: 57000...  Training loss: 1.6510...  0.0932 sec/batch\n",
      "Epoch: 8/15...  Training Step: 58000...  Training loss: 1.6872...  0.0842 sec/batch\n",
      "Epoch: 8/15...  Training Step: 59000...  Training loss: 1.6600...  0.1607 sec/batch\n",
      "Epoch: 8/15...  Training Step: 60000...  Training loss: 1.4768...  0.1121 sec/batch\n",
      "Epoch: 8/15...  Training Step: 61000...  Training loss: 1.5425...  0.1280 sec/batch\n",
      "Epoch: 9/15...  Training Step: 62000...  Training loss: 1.5027...  0.1116 sec/batch\n",
      "Epoch: 9/15...  Training Step: 63000...  Training loss: 1.4831...  0.1133 sec/batch\n",
      "Epoch: 9/15...  Training Step: 64000...  Training loss: 1.6429...  0.0903 sec/batch\n",
      "Epoch: 9/15...  Training Step: 65000...  Training loss: 1.6466...  0.0881 sec/batch\n",
      "Epoch: 9/15...  Training Step: 66000...  Training loss: 1.5642...  0.0875 sec/batch\n",
      "Epoch: 9/15...  Training Step: 67000...  Training loss: 1.4823...  0.0905 sec/batch\n",
      "Epoch: 9/15...  Training Step: 68000...  Training loss: 1.5986...  0.1130 sec/batch\n",
      "Epoch: 10/15...  Training Step: 69000...  Training loss: 1.5394...  0.0898 sec/batch\n",
      "Epoch: 10/15...  Training Step: 70000...  Training loss: 1.5456...  0.0964 sec/batch\n",
      "Epoch: 10/15...  Training Step: 71000...  Training loss: 1.5536...  0.0952 sec/batch\n",
      "Epoch: 10/15...  Training Step: 72000...  Training loss: 1.7656...  0.0865 sec/batch\n",
      "Epoch: 10/15...  Training Step: 73000...  Training loss: 1.5233...  0.1259 sec/batch\n",
      "Epoch: 10/15...  Training Step: 74000...  Training loss: 1.6934...  0.0926 sec/batch\n",
      "Epoch: 10/15...  Training Step: 75000...  Training loss: 1.6153...  0.0946 sec/batch\n",
      "Epoch: 10/15...  Training Step: 76000...  Training loss: 1.5794...  0.0868 sec/batch\n",
      "Epoch: 11/15...  Training Step: 77000...  Training loss: 1.7309...  0.0843 sec/batch\n",
      "Epoch: 11/15...  Training Step: 78000...  Training loss: 1.6564...  0.0887 sec/batch\n",
      "Epoch: 11/15...  Training Step: 79000...  Training loss: 1.5248...  0.0911 sec/batch\n",
      "Epoch: 11/15...  Training Step: 80000...  Training loss: 1.5651...  0.0835 sec/batch\n",
      "Epoch: 11/15...  Training Step: 81000...  Training loss: 1.5251...  0.0898 sec/batch\n",
      "Epoch: 11/15...  Training Step: 82000...  Training loss: 1.5441...  0.0895 sec/batch\n",
      "Epoch: 11/15...  Training Step: 83000...  Training loss: 1.5586...  0.1009 sec/batch\n",
      "Epoch: 12/15...  Training Step: 84000...  Training loss: 1.6219...  0.0927 sec/batch\n",
      "Epoch: 12/15...  Training Step: 85000...  Training loss: 1.7036...  0.0860 sec/batch\n",
      "Epoch: 12/15...  Training Step: 86000...  Training loss: 1.6041...  0.0932 sec/batch\n",
      "Epoch: 12/15...  Training Step: 87000...  Training loss: 1.4429...  0.1265 sec/batch\n",
      "Epoch: 12/15...  Training Step: 88000...  Training loss: 1.5227...  0.1063 sec/batch\n",
      "Epoch: 12/15...  Training Step: 89000...  Training loss: 1.6213...  0.0958 sec/batch\n",
      "Epoch: 12/15...  Training Step: 90000...  Training loss: 1.7280...  0.0891 sec/batch\n",
      "Epoch: 12/15...  Training Step: 91000...  Training loss: 1.5596...  0.0871 sec/batch\n",
      "Epoch: 13/15...  Training Step: 92000...  Training loss: 1.5702...  0.0822 sec/batch\n",
      "Epoch: 13/15...  Training Step: 93000...  Training loss: 1.5382...  0.1014 sec/batch\n",
      "Epoch: 13/15...  Training Step: 94000...  Training loss: 1.5744...  0.0906 sec/batch\n",
      "Epoch: 13/15...  Training Step: 95000...  Training loss: 1.6798...  0.1348 sec/batch\n",
      "Epoch: 13/15...  Training Step: 96000...  Training loss: 1.5599...  0.0877 sec/batch\n",
      "Epoch: 13/15...  Training Step: 97000...  Training loss: 1.4970...  0.2115 sec/batch\n",
      "Epoch: 13/15...  Training Step: 98000...  Training loss: 1.5963...  0.1126 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/15...  Training Step: 99000...  Training loss: 1.6740...  0.1416 sec/batch\n",
      "Epoch: 14/15...  Training Step: 100000...  Training loss: 1.5571...  0.1190 sec/batch\n",
      "Epoch: 14/15...  Training Step: 101000...  Training loss: 1.4686...  0.1068 sec/batch\n",
      "Epoch: 14/15...  Training Step: 102000...  Training loss: 1.4647...  0.1207 sec/batch\n",
      "Epoch: 14/15...  Training Step: 103000...  Training loss: 1.5873...  0.0854 sec/batch\n",
      "Epoch: 14/15...  Training Step: 104000...  Training loss: 1.6049...  0.1167 sec/batch\n",
      "Epoch: 14/15...  Training Step: 105000...  Training loss: 1.6603...  0.1111 sec/batch\n",
      "Epoch: 14/15...  Training Step: 106000...  Training loss: 1.6969...  0.1089 sec/batch\n",
      "Epoch: 15/15...  Training Step: 107000...  Training loss: 1.6003...  0.1072 sec/batch\n",
      "Epoch: 15/15...  Training Step: 108000...  Training loss: 1.5646...  0.1189 sec/batch\n",
      "Epoch: 15/15...  Training Step: 109000...  Training loss: 1.5841...  0.1075 sec/batch\n",
      "Epoch: 15/15...  Training Step: 110000...  Training loss: 1.6449...  0.1145 sec/batch\n",
      "Epoch: 15/15...  Training Step: 111000...  Training loss: 1.5545...  0.0841 sec/batch\n",
      "Epoch: 15/15...  Training Step: 112000...  Training loss: 1.5700...  0.1050 sec/batch\n",
      "Epoch: 15/15...  Training Step: 113000...  Training loss: 1.5870...  0.1098 sec/batch\n",
      "Epoch: 15/15...  Training Step: 114000...  Training loss: 1.6723...  0.1113 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "# Save every N iterations\n",
    "save_every_n = 1000\n",
    "show_every_n = 1000\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "config=tf.ConfigProto(\n",
    "    device_count={\"CPU\":16}, \n",
    "    inter_op_parallelism_threads=16, \n",
    "    intra_op_parallelism_threads=16,\n",
    ")\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            if (counter % show_every_n == 0):\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(counter),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/e{}_i{}_l{}.ckpt\".format(e+1, counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/e{}_i{}_l{}.ckpt\".format(e+1, counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/e15_i114540_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/e15_i111000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/e15_i112000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/e15_i113000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/e15_i114000_l128.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/e15_i114540_l128.ckpt\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/e15_i114540_l128.ckpt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/e15_i114540_l128.ckpt\n",
      "Fëanor and Fingolfin and Men were so at the top and saw the brothers that the stars of hard they could go had a ground of he shall. In the trees of the treps had some words; and he had said at his fear and sheer on their booled; and the trees at tell her. But a bow her stands say and the boat on the despair of the sea and and shining, and he had nearer they came to the store of a long shoping they would see the black beard, and shall see. The white was to the saunt of the song and shoulders of any stirred. ‘The woods was been a between words and wooded the with a great waters as a wood with take one of sat and saw a good.’ I called the sense of the March of Sauloth in the Song of the Silmarils of the Elvens of the Misty Ring of the Naun he shall not come on a s\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp1 = sample(checkpoint, 750, lstm_size, len(vocab), prime=\"Fëanor and Fingolfin\")\n",
    "print(samp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/e15_i114540_l128.ckpt\n",
      "Beren and Luthien, and they deven at how seemed in. ‘I had been,” he said and some are that still huse here again, and seen hobbits of the song of Minas Tirith and there the shall a long first shield they seemed alone; but the still seeks and burrent, standed on the ships was a shadow about the stars in take the learn of the still of those that here, and she can hold on a ships of the time as that seen, but they shall not hear. He was a blanken already he soon, and that he were the black, and they hoursed to the star of a stream, still as the lands of his would heard and which think went the listens that the same and searth and the leaves of the stofter of the Might of the Elves of the North of the Ring of Gondor. But a golden hard seemers and as any wellow.\n"
     ]
    }
   ],
   "source": [
    "samp2 = sample(checkpoint, 750, lstm_size, len(vocab), prime=\"Beren and Luthien\")\n",
    "print(samp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/e15_i114540_l128.ckpt\n",
      "Aragorn and Arwen; from. Bilbo has nucking if the stranges tone that as were brought him on the shape, they seemed and set. Then they was a stone tone to him, and he had sinted a middle of through the stars, that seemed to the stone as they had been stared and best.\n",
      "\n",
      "‘I was netted in still a little andow that was all the world of his head, and have the less took were to here with the hands of Minas Tarin. But they was a laster of stand or to hobbits with him, and say of this hall of the Merry of the Noldor of the Men the listentar, and they had become of the still, but it were sharped a bear of the deal of this shore of the Stirgount in his, and then the lunged west which he shall be to somp them as he saw the time on the stoused sea, and so there were forde\n"
     ]
    }
   ],
   "source": [
    "samp3 = sample(checkpoint, 750, lstm_size, len(vocab), prime=\"Aragorn and Arwen\")\n",
    "print(samp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/e15_i114540_l128.ckpt\n",
      "Smaug, Bilbo and Gandalf alone in hobbits than they deven a foring, both a should best, and to a stories seemed at our first and star at one back. There had too both and the time with his head and theys, but they heard to him were battle track there. But he walls to the holain.\n",
      "\n",
      "‘I came up and the house though you set him. If they had sat to think, and how the white, they were things, and his hound had been became to a ground to an is the sons, and he had brought the stone, and all the wise and a shone of the hand of these sent of as had say the tankes and to his sank at a book of the three a steper, but in his same traid and was bore and all them out of his far the last and ferchour at, but the rise of to the high tale. I had some hare or belossed in the station.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samp4 = sample(checkpoint, 750, lstm_size, len(vocab), prime=\"Smaug, Bilbo and Gandalf\")\n",
    "print(samp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/e15_i114540_l128.ckpt\n",
      "Ents and Entwives of Men through the Saruman. Then went and bethe was the thought; and he was buitted is beated, to see helped to her breached the thought of the Marth that hart the tines.\n",
      "\n",
      "‘To that shall all the lisses. But the hand of the shirr than any hand was taken that the song of the Morner our time they had started and that set in the top of the horn of the Mountain, and as a bottom of a bragening wonder in the way with his things and strided of the bright. All there were a large shadow of the sound of the worm in her horses to the song of the Shire, and the stars that with the tares of the waters of his tried of hard the strish was business of the water of his top and as all the same and the white horse and seemed;\n",
      "\n",
      "\n",
      "\n",
      "They were bundled the shadow th\n"
     ]
    }
   ],
   "source": [
    "samp5 = sample(checkpoint, 750, lstm_size, len(vocab), prime=\"Ents and Entwives\")\n",
    "print(samp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/e15_i114540_l128.ckpt\n",
      "A new fellowship of the rings with a bank, shorter at all the world.\n",
      "\n",
      "There was he sang oft, but at least the tarred were they wish as he had said they sat on it and hurry that the shadow they had a galrilings and here. All to the waters was been began the bear and tried in the dark bent which she stowed.\n",
      "\n",
      "‘Then it was neas of stories that then then, best a some as they sound in that they deep and to the day is them. Bilbo were not a side to a lord, but that his shorls all the way or horn, all the like sang, and then the way, what were stay. The storiss though we said.\n",
      "\n",
      "‘That say and horry tha the with was the what all him. As I should tell we there some soon at his fellows and his tale as all a long wars. A time was strong, and who were all them to time. He seemed, se\n"
     ]
    }
   ],
   "source": [
    "samp6 = sample(checkpoint, 750, lstm_size, len(vocab), prime=\"A new fellowship of the ring\")\n",
    "print(samp6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
